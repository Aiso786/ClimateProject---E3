{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import opendatasets as od\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "#!pip3 install keras-tuner --upgrade\n",
    "#!pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./ship-and-iceberg-images\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/saurabhbagchi/ship-and-iceberg-images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/home/apprenant/PycharmProjects/ClimateProject---E3/ship-and-iceberg-images/input_data.npz'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npz = np.load('/home/apprenant/PycharmProjects/ClimateProject---E3/Data analysis/ship-and-iceberg-images/input_data.npz')\n",
    "\n",
    "x = npz['X_train']\n",
    "y = npz['Y_train']\n",
    "del npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of picture: (4113, 75, 75, 3)\n",
      "shape of picture: (4113,)\n"
     ]
    }
   ],
   "source": [
    "print('shape of picture: {}'.format(x.shape))\n",
    "print('shape of picture: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-74-051343f07151>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-74-051343f07151>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    X_train, X_valtest, y_train, y_valtest = train_test_split(x,y, test_size=0.2 random_state=1, stratify=y)\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# First split the data in two sets, 80% for training, 20% for Val/Test)\n",
    "X_train, X_valtest, y_train, y_valtest = train_test_split(x,y, test_size=0.2 random_state=1, stratify=y)\n",
    "\n",
    "# Second split the 20% into validation and test sets\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_valtest, y_valtest, test_size=0.8, random_state=1, stratify=y_valtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.array(X_train).shape)\n",
    "print(np.array(X_val).shape)\n",
    "print(np.array(X_test).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_val).shape)\n",
    "print(np.array(y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    # create model object\n",
    "    model = keras.Sequential([\n",
    "    #adding first convolutional layer    \n",
    "    keras.layers.Conv2D(\n",
    "        #adding filter \n",
    "        filters=hp.Int('conv_1_filter', min_value=5, max_value=128, step=16),\n",
    "        # adding filter size or kernel size\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
    "        #activation function\n",
    "        activation='relu',\n",
    "        input_shape=(75,75,3)),\n",
    "    # adding second convolutional layer \n",
    "    keras.layers.Conv2D(\n",
    "        #adding filter \n",
    "        filters=hp.Int('conv_2_filter', min_value=5, max_value=64, step=16),\n",
    "        #adding filter size or kernel size\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n",
    "        #activation function\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    # adding flatten layer    \n",
    "    keras.layers.Flatten(),\n",
    "    # adding dense layer    \n",
    "    keras.layers.Dense(\n",
    "        units=hp.Int('dense_1_units', min_value=5, max_value=128, step=16),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.BatchNormalization(),    \n",
    "    # output layer    \n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "    ])\n",
    "    #compilation of model\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 54s]\n",
      "val_accuracy: 0.5516194105148315\n",
      "\n",
      "Best val_accuracy So Far: 0.73886638879776\n",
      "Total elapsed time: 00h 03m 36s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "#creating randomsearch object\n",
    "tuner = keras_tuner.RandomSearch(build_model,\n",
    "                    objective='val_accuracy',\n",
    "                    max_trials = 2,\n",
    "                    overwrite=True)\n",
    "# search best parameter\n",
    "tuner.search(X_train,y_train,epochs=3,validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 71, 71, 58)        4408      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 67, 67, 58)        84158     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 67, 67, 58)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 260362)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 58)                15101054  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 58)                232       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                590       \n",
      "=================================================================\n",
      "Total params: 15,190,442\n",
      "Trainable params: 15,190,326\n",
      "Non-trainable params: 116\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tuner.get_best_models(num_models=1)[0]\n",
    "#summary of best model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "70/70 [==============================] - 51s 724ms/step - loss: 0.0420 - accuracy: 0.9851 - val_loss: 1.2196 - val_accuracy: 0.8016\n",
      "Epoch 2/20\n",
      "70/70 [==============================] - 45s 645ms/step - loss: 0.0499 - accuracy: 0.9842 - val_loss: 1.1219 - val_accuracy: 0.8057\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - 46s 664ms/step - loss: 0.0416 - accuracy: 0.9842 - val_loss: 1.8791 - val_accuracy: 0.7571\n",
      "Epoch 4/20\n",
      "70/70 [==============================] - 47s 665ms/step - loss: 0.0269 - accuracy: 0.9910 - val_loss: 1.2649 - val_accuracy: 0.8178\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - 47s 673ms/step - loss: 0.0433 - accuracy: 0.9869 - val_loss: 1.0199 - val_accuracy: 0.8178\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - 46s 662ms/step - loss: 0.0176 - accuracy: 0.9928 - val_loss: 1.0839 - val_accuracy: 0.8300\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - 45s 645ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 1.1383 - val_accuracy: 0.8138\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - 45s 649ms/step - loss: 0.0187 - accuracy: 0.9928 - val_loss: 1.0214 - val_accuracy: 0.8178\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - 45s 645ms/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 1.8597 - val_accuracy: 0.7652\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - 45s 644ms/step - loss: 0.0214 - accuracy: 0.9923 - val_loss: 1.3939 - val_accuracy: 0.7530\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - 45s 644ms/step - loss: 0.0433 - accuracy: 0.9833 - val_loss: 1.7099 - val_accuracy: 0.8097\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - 45s 645ms/step - loss: 0.0369 - accuracy: 0.9892 - val_loss: 1.2821 - val_accuracy: 0.8502\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - 45s 646ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 1.2936 - val_accuracy: 0.8219\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - 45s 645ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 1.4601 - val_accuracy: 0.8057\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - 45s 644ms/step - loss: 0.0245 - accuracy: 0.9932 - val_loss: 1.7880 - val_accuracy: 0.7814\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - 45s 647ms/step - loss: 0.0583 - accuracy: 0.9766 - val_loss: 1.3050 - val_accuracy: 0.8016\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - 45s 642ms/step - loss: 0.0470 - accuracy: 0.9829 - val_loss: 0.9068 - val_accuracy: 0.8664\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - 46s 659ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 1.2867 - val_accuracy: 0.8057\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - 47s 668ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.9709 - val_accuracy: 0.8623\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - 45s 637ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 1.3430 - val_accuracy: 0.7935\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "          epochs=20,\n",
    "          validation_split=0.1,initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042002</td>\n",
       "      <td>0.985135</td>\n",
       "      <td>1.219629</td>\n",
       "      <td>0.801619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.049861</td>\n",
       "      <td>0.984234</td>\n",
       "      <td>1.121918</td>\n",
       "      <td>0.805668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041568</td>\n",
       "      <td>0.984234</td>\n",
       "      <td>1.879126</td>\n",
       "      <td>0.757085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026945</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>1.264891</td>\n",
       "      <td>0.817814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.043312</td>\n",
       "      <td>0.986937</td>\n",
       "      <td>1.019869</td>\n",
       "      <td>0.817814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.042002  0.985135  1.219629      0.801619\n",
       "1  0.049861  0.984234  1.121918      0.805668\n",
       "2  0.041568  0.984234  1.879126      0.757085\n",
       "3  0.026945  0.990991  1.264891      0.817814\n",
       "4  0.043312  0.986937  1.019869      0.817814"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#create a dataframe of the model training history\n",
    "results = pd.DataFrame(history.history)\n",
    "results.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
